{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment analysis of the Persian text with word embedding & frequency word / classification .ipynb",
      "provenance": [],
      "collapsed_sections": [
        "5FQA6ms841GL",
        "HLpJAUUC7SFz",
        "bnOyG5AcbAir",
        "HIa-bRVB7_cp",
        "Mhounpfs8GRZ",
        "E1MZtoBo8I5o",
        "GT2_TkQu7s7c",
        "6fbj-Mx47vdB"
      ],
      "authorship_tag": "ABX9TyOMTtXqDf7uwQ/aKsM9OKei",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sanazzzmi/Sentiment_analysis_of_the_Persian_text_with_word_embedding_-_frequency_word/blob/main/Sentiment_analysis_of_the_Persian_text_with_word_embedding_%26_frequency_word_classification_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### install and import data"
      ],
      "metadata": {
        "id": "Szivt7qr79nm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1ol0fYR9-X2",
        "outputId": "4b4eec75-409b-40cb-de74-cc3b541e5be6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hazm\n",
        "!test -f resources-0.5.zip || curl -LO https://github.com/sobhe/hazm/releases/download/v0.5/resources-0.5.zip\n",
        "!test -d resources || ( mkdir -p resources && cd resources && unzip ../resources-0.5.zip )\n",
        "\n",
        "import hazm\n",
        "from __future__ import unicode_literals\n",
        "from hazm import *\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "#dataset\n",
        "dataset = pd.read_excel('/content/drive/MyDrive/data/digikala_data/digikala.xlsx')\n"
      ],
      "metadata": {
        "id": "atVCnVmY4RQF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c942106-5391-436d-e758-eb4e5a9eb8d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting hazm\n",
            "  Downloading hazm-0.7.0-py3-none-any.whl (316 kB)\n",
            "\u001b[K     |████████████████████████████████| 316 kB 5.0 MB/s \n",
            "\u001b[?25hCollecting libwapiti>=0.2.1\n",
            "  Downloading libwapiti-0.2.1.tar.gz (233 kB)\n",
            "\u001b[K     |████████████████████████████████| 233 kB 26.0 MB/s \n",
            "\u001b[?25hCollecting nltk==3.3\n",
            "  Downloading nltk-3.3.0.zip (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 31.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.3->hazm) (1.15.0)\n",
            "Building wheels for collected packages: nltk, libwapiti\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.3-py3-none-any.whl size=1394487 sha256=ebb111bc26a5019d6b814d87ea059721f344b610f99e900de62b4383cd37922c\n",
            "  Stored in directory: /root/.cache/pip/wheels/9b/fd/0c/d92302c876e5de87ebd7fc0979d82edb93e2d8d768bf71fac4\n",
            "  Building wheel for libwapiti (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for libwapiti: filename=libwapiti-0.2.1-cp37-cp37m-linux_x86_64.whl size=154002 sha256=1e580bb1d9dd5f5236a1e4dac68f365a428a0c4f518befa4ef168811b90cfbda\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/b2/5b/0fe4b8f5c0e65341e8ea7bb3f4a6ebabfe8b1ac31322392dbf\n",
            "Successfully built nltk libwapiti\n",
            "Installing collected packages: nltk, libwapiti, hazm\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "Successfully installed hazm-0.7.0 libwapiti-0.2.1 nltk-3.3\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   654  100   654    0     0   3424      0 --:--:-- --:--:-- --:--:--  3424\n",
            "100 29.1M  100 29.1M    0     0  44.4M      0 --:--:-- --:--:-- --:--:-- 44.4M\n",
            "Archive:  ../resources-0.5.zip\n",
            "  inflating: chunker.model           \n",
            "  inflating: langModel.mco           \n",
            "   creating: lib/\n",
            "  inflating: lib/liblinear-1.8.jar   \n",
            "  inflating: lib/libsvm.jar          \n",
            "  inflating: lib/log4j.jar           \n",
            "  inflating: malt.jar                \n",
            "  inflating: postagger.model         \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.comment = dataset.comment.apply(str)\n",
        "dataset.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "TlIycvem1cQs",
        "outputId": "1eb3e2fa-39ed-44e2-c0a3-fadea7465599"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1a39d8d1-9645-42f5-9b44-c23e4cebe845\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>product_id</th>\n",
              "      <th>product_title</th>\n",
              "      <th>title_en</th>\n",
              "      <th>user_id</th>\n",
              "      <th>likes</th>\n",
              "      <th>dislikes</th>\n",
              "      <th>verification_status</th>\n",
              "      <th>recommend</th>\n",
              "      <th>title</th>\n",
              "      <th>comment</th>\n",
              "      <th>advantages</th>\n",
              "      <th>disadvantages</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3692</td>\n",
              "      <td>ماوس بی‌سیم لاجیتک مدل M325</td>\n",
              "      <td>IT</td>\n",
              "      <td>989472</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>verified</td>\n",
              "      <td>\\N</td>\n",
              "      <td>NaN</td>\n",
              "      <td>واقعا عالیه. من که ازش خیلی راضیم</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>90213</td>\n",
              "      <td>شارژر همراه شیاومی مدل NDY-02-AN با ظرفیت 1000...</td>\n",
              "      <td>AC</td>\n",
              "      <td>3862150</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>verified</td>\n",
              "      <td>recommended</td>\n",
              "      <td>واقعاً عالیه</td>\n",
              "      <td>سلام، قبل اینکه نظرم رو بگم میخواستم به یک موض...</td>\n",
              "      <td>[\"عمر طولانی\\r\",\"افت بسیار کم میزان شارژ\\r\",\"ا...</td>\n",
              "      <td>[\"ندارد\"]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>59473</td>\n",
              "      <td>یدک پولیشر میکروفایبر مهسان مدل 20119</td>\n",
              "      <td>HW</td>\n",
              "      <td>626843</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>verified</td>\n",
              "      <td>not_recommended</td>\n",
              "      <td>خیلی سخت حوله اش در میاد</td>\n",
              "      <td>گیره های فلزی خیلی سخت تا میشوند و لذا حوله را...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>120499</td>\n",
              "      <td>گوشی موبایل هوآوی آنر مدل 5X KIW-L21 دو سیم‌کارت</td>\n",
              "      <td>MO</td>\n",
              "      <td>786887</td>\n",
              "      <td>6</td>\n",
              "      <td>11</td>\n",
              "      <td>verified</td>\n",
              "      <td>no_idea</td>\n",
              "      <td>گوشی مقرون به صرفه</td>\n",
              "      <td>همه چیز در رابطه با ظاهر این گوشی بسیار خوب اس...</td>\n",
              "      <td>[\"صفحه نمایش پرنور و با کیفیت\\r\",\"کیفیت بالای ...</td>\n",
              "      <td>[\"کیفیت پایین اسپیکر\\r\",\"حاشیه خالی زیر صفحه ن...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>67200</td>\n",
              "      <td>شارژر همراه شیائومی مدل Mi ظرفیت 5000 میلی آمپ...</td>\n",
              "      <td>AC</td>\n",
              "      <td>854531</td>\n",
              "      <td>19</td>\n",
              "      <td>4</td>\n",
              "      <td>verified</td>\n",
              "      <td>no_idea</td>\n",
              "      <td>ابعاد، استحکام و نگهداری شارژ مناسب</td>\n",
              "      <td>اگر ظرفیتش براتون کافیه حتما بخرید.\\r\\nیه شارژ...</td>\n",
              "      <td>[\"ظریف و زیبا و باریک\\r\",\"بدنه محکم و با دوام\"]</td>\n",
              "      <td>[\"ظرفیت متوسط\"]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1a39d8d1-9645-42f5-9b44-c23e4cebe845')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1a39d8d1-9645-42f5-9b44-c23e4cebe845 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1a39d8d1-9645-42f5-9b44-c23e4cebe845');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   product_id  ...                                      disadvantages\n",
              "0        3692  ...                                                NaN\n",
              "1       90213  ...                                          [\"ندارد\"]\n",
              "2       59473  ...                                                NaN\n",
              "3      120499  ...  [\"کیفیت پایین اسپیکر\\r\",\"حاشیه خالی زیر صفحه ن...\n",
              "4       67200  ...                                    [\"ظرفیت متوسط\"]\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.fa.300.bin.gz\n",
        "!gunzip /content/cc.fa.300.bin.gz\n",
        "!pip install fasttext\n",
        "\n",
        "import fasttext \n",
        "\n",
        "%time\n",
        "model = fasttext.load_model(\"/content/cc.fa.300.bin\")"
      ],
      "metadata": {
        "id": "iQeNWHff4RUN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a290cf5-3ddb-4738-8fbd-28b4bed7f40e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-02-01 15:10:07--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.fa.300.bin.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.75.142, 104.22.74.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4502524724 (4.2G) [application/octet-stream]\n",
            "Saving to: ‘cc.fa.300.bin.gz’\n",
            "\n",
            "cc.fa.300.bin.gz    100%[===================>]   4.19G  25.0MB/s    in 1m 57s  \n",
            "\n",
            "2022-02-01 15:12:04 (36.7 MB/s) - ‘cc.fa.300.bin.gz’ saved [4502524724/4502524724]\n",
            "\n",
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
            "\u001b[K     |████████████████████████████████| 68 kB 3.1 MB/s \n",
            "\u001b[?25hCollecting pybind11>=2.2\n",
            "  Using cached pybind11-2.9.0-py2.py3-none-any.whl (210 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from fasttext) (57.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fasttext) (1.19.5)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp37-cp37m-linux_x86_64.whl size=3124503 sha256=442a2715e9126533aaa3dc209581f0aae828aa0b7d7da2ae3b2b7b0875d60f43\n",
            "  Stored in directory: /root/.cache/pip/wheels/4e/ca/bf/b020d2be95f7641801a6597a29c8f4f19e38f9c02a345bab9b\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.2 pybind11-2.9.0\n",
            "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
            "Wall time: 6.44 µs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-GSfYOVXF8t"
      },
      "source": [
        "### train test split for CNN modle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.groupby('recommend').count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "xt6eohBh1qsF",
        "outputId": "c06c7b0d-840f-472d-e9b5-6af9110cbbd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ab7f68ab-fde6-42d9-bf49-a9eaa71743d2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>product_id</th>\n",
              "      <th>product_title</th>\n",
              "      <th>title_en</th>\n",
              "      <th>user_id</th>\n",
              "      <th>likes</th>\n",
              "      <th>dislikes</th>\n",
              "      <th>verification_status</th>\n",
              "      <th>title</th>\n",
              "      <th>comment</th>\n",
              "      <th>advantages</th>\n",
              "      <th>disadvantages</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recommend</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>\\N</th>\n",
              "      <td>36382</td>\n",
              "      <td>36382</td>\n",
              "      <td>36382</td>\n",
              "      <td>36382</td>\n",
              "      <td>36382</td>\n",
              "      <td>36382</td>\n",
              "      <td>36382</td>\n",
              "      <td>35106</td>\n",
              "      <td>36382</td>\n",
              "      <td>16241</td>\n",
              "      <td>11953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>no_idea</th>\n",
              "      <td>10536</td>\n",
              "      <td>10536</td>\n",
              "      <td>10536</td>\n",
              "      <td>10536</td>\n",
              "      <td>10536</td>\n",
              "      <td>10536</td>\n",
              "      <td>10536</td>\n",
              "      <td>10207</td>\n",
              "      <td>10536</td>\n",
              "      <td>3840</td>\n",
              "      <td>3746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>not_recommended</th>\n",
              "      <td>16110</td>\n",
              "      <td>16110</td>\n",
              "      <td>16110</td>\n",
              "      <td>16110</td>\n",
              "      <td>16110</td>\n",
              "      <td>16110</td>\n",
              "      <td>16110</td>\n",
              "      <td>15363</td>\n",
              "      <td>16110</td>\n",
              "      <td>4881</td>\n",
              "      <td>6256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recommended</th>\n",
              "      <td>36972</td>\n",
              "      <td>36972</td>\n",
              "      <td>36972</td>\n",
              "      <td>36972</td>\n",
              "      <td>36972</td>\n",
              "      <td>36972</td>\n",
              "      <td>36972</td>\n",
              "      <td>36054</td>\n",
              "      <td>36972</td>\n",
              "      <td>17279</td>\n",
              "      <td>12166</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ab7f68ab-fde6-42d9-bf49-a9eaa71743d2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ab7f68ab-fde6-42d9-bf49-a9eaa71743d2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ab7f68ab-fde6-42d9-bf49-a9eaa71743d2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                 product_id  product_title  ...  advantages  disadvantages\n",
              "recommend                                   ...                           \n",
              "\\N                    36382          36382  ...       16241          11953\n",
              "no_idea               10536          10536  ...        3840           3746\n",
              "not_recommended       16110          16110  ...        4881           6256\n",
              "recommended           36972          36972  ...       17279          12166\n",
              "\n",
              "[4 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.recommend[dataset.recommend == '\\\\N'] = 2\n",
        "dataset.recommend[dataset.recommend == 'no_idea'] = 2\n",
        "dataset.recommend[dataset.recommend == 'not_recommended'] = 3\n",
        "dataset.recommend[dataset.recommend == 'recommended'] = 1\n",
        "\n",
        "df_final = dataset[['recommend', 'comment']]\n",
        "df_final.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "B6wf8Z1D1tUE",
        "outputId": "bb19bdbe-a2a2-4a26-b9d7-0c39feda9ef4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-50e2defa-2b6f-485f-a31a-fb108a05a90b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>recommend</th>\n",
              "      <th>comment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>واقعا عالیه. من که ازش خیلی راضیم</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>سلام، قبل اینکه نظرم رو بگم میخواستم به یک موض...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>گیره های فلزی خیلی سخت تا میشوند و لذا حوله را...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>همه چیز در رابطه با ظاهر این گوشی بسیار خوب اس...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>اگر ظرفیتش براتون کافیه حتما بخرید.\\r\\nیه شارژ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-50e2defa-2b6f-485f-a31a-fb108a05a90b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-50e2defa-2b6f-485f-a31a-fb108a05a90b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-50e2defa-2b6f-485f-a31a-fb108a05a90b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "  recommend                                            comment\n",
              "0         2                  واقعا عالیه. من که ازش خیلی راضیم\n",
              "1         1  سلام، قبل اینکه نظرم رو بگم میخواستم به یک موض...\n",
              "2         3  گیره های فلزی خیلی سخت تا میشوند و لذا حوله را...\n",
              "3         2  همه چیز در رابطه با ظاهر این گوشی بسیار خوب اس...\n",
              "4         2  اگر ظرفیتش براتون کافیه حتما بخرید.\\r\\nیه شارژ..."
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4WLV4-mbfe6",
        "outputId": "30e97194-f0da-48e1-910d-f5693fc9a65d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Posetive count 36972\n",
            "Negetive count 16110\n",
            "Natural  count 46918\n",
            "\n",
            "Total    count 100000\n",
            "\n",
            "Posetive count :  \n",
            " ['اگه میخواید یه اسپیکر همراتون باشه که همیشه و همه جا ببرید و وصل کنید به موبایل خوبه \\nدر نگاه اول تعجب میکنید که اسپیکر به این کوچیکی همچین صدایی داره\\nاما اگر میخواید یه اسپیکر عالی داشته باشید این اون عالیه نیست \\nمدل Square Box ۲ فوق العاده ست یا سونی SRRXB۱۰۰ این مدل فقط برای این خوبه که توی محیط کار یه آهنگ با صدای کم گوش کنید \\nتو صدای بلند حرفی برای گفتن نداره نسبت به دو مدلی هم که گفتم کیفیت و تفکیک صدای متوسطی داره، اما با این حال نسبت به سایر برندهای این دره قیمت بهتره', 1]\n",
            "Negetive count :  \n",
            " ['به گوشی نوت ۵ نمیخورد.', 3]\n",
            "unknown  count :  \n",
            " ['دیروز به\\u200cدستم رسید، مونتاژش کار سختی نبود، از لحاظ کیفیت عالیه ولی خوب قیمت بالایی داره، اگه سوالی بود در خدمتم', 2]\n",
            "Total    count 53082\n"
          ]
        }
      ],
      "source": [
        "def CleanPersianText(text):\n",
        "  _normalizer = hazm.Normalizer()\n",
        "  text = _normalizer.normalize(text)\n",
        "  return text\n",
        "\n",
        "revlist = list(map(lambda x: [CleanPersianText(x[0]),x[1]],zip(dataset['comment'],dataset['recommend'])))\n",
        "pos=list(filter(lambda x: x[1] == 1,revlist))\n",
        "nat=list(filter(lambda x: x[1] == 2,revlist))\n",
        "neg=list(filter(lambda x: x[1] == 3,revlist))\n",
        "\n",
        "revlist_shuffle = pos[:] + neg[:]\n",
        "random.shuffle(revlist_shuffle)\n",
        "\n",
        "print(\"Posetive count {}\".format(len(pos)))\n",
        "print(\"Negetive count {}\".format(len(neg)))\n",
        "print(\"Natural  count {}\".format(len(nat)))\n",
        "print()\n",
        "print(\"Total    count {}\".format(len(revlist)))\n",
        "print()\n",
        "print(\"Posetive count : \",\"\\n\",pos[random.randrange(1,len(pos))])\n",
        "print(\"Negetive count : \",\"\\n\",neg[random.randrange(1,len(neg))])\n",
        "print(\"unknown  count : \",\"\\n\",nat[random.randrange(1,len(nat))])\n",
        "print(\"Total    count {}\".format(len(revlist_shuffle)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0gEYJuyHdpIS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d212699-2dae-4dce-edf4-e0b9f89d76d9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((47773, 20, 300), (5308, 20, 300), (47773, 2), (5308, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "vector_size = 300 \n",
        "max_no_tokens = 20 \n",
        "import numpy as np\n",
        "import keras.backend as K\n",
        "train_size = int(0.9*(len(revlist_shuffle)))\n",
        "test_size = int(0.1*(len(revlist_shuffle)))#lstm\n",
        "indexes = set(np.random.choice(len(revlist_shuffle), train_size + test_size, replace=False))\n",
        "\n",
        "x_train = np.zeros((train_size, max_no_tokens, vector_size), dtype=K.floatx())\n",
        "y_train = np.zeros((train_size, 2), dtype=np.int32)\n",
        "\n",
        "x_test = np.zeros((test_size, max_no_tokens, vector_size), dtype=K.floatx())\n",
        "y_test = np.zeros((test_size, 2), dtype=np.int32)\n",
        "\n",
        "\n",
        "for i, index in enumerate(indexes):\n",
        "  text_words = hazm.word_tokenize(revlist_shuffle[index][0])\n",
        "  for t in range(0,len(text_words)):\n",
        "    if t >= max_no_tokens:\n",
        "      break\n",
        "\n",
        "    if text_words[t] not in model.words:\n",
        "      continue\n",
        "    if i < train_size:\n",
        "      x_train[i, t, :] = model.get_word_vector(text_words[t])\n",
        "    else:\n",
        "      x_test[i - train_size, t, :] = model.get_word_vector(text_words[t])\n",
        "\n",
        "  if i < train_size:\n",
        "    y_train[i, :] = [1.0, 0.0] if revlist_shuffle[index][1] == 3 else [0.0, 1.0]\n",
        "  else:\n",
        "    y_test[i - train_size, :] = [1.0, 0.0] if revlist_shuffle[index][1] == 3 else [0.0, 1.0]\n",
        "   \n",
        "x_train.shape,x_test.shape,y_train.shape,y_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FQA6ms841GL"
      },
      "source": [
        "### **Article idea**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BI2micWT93Zg"
      },
      "outputs": [],
      "source": [
        "text = [x[0] for x in revlist_shuffle ]\n",
        "y = [x[1] for x in revlist_shuffle ]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "token = Tokenizer()\n",
        "token.fit_on_texts(text)"
      ],
      "metadata": {
        "id": "S9UdeCTycgqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size  = len(token.word_index) + 1\n",
        "vocab_size"
      ],
      "metadata": {
        "id": "0nJgJCnScixg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3237cbf-e86c-4acd-ab43-c946e6277aa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51526"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7MG7gv3USkk",
        "outputId": "6b753eae-bb0a-4138-e410-419492109a7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[7, 13, 723, 1427, 78, 44, 4, 55, 27, 403, 1, 8329, 256, 12], [2, 930, 709, 24, 24, 145, 1, 22785, 45], [15, 172, 183, 1, 990, 123, 11, 61, 554, 1, 66, 1904]]\n"
          ]
        }
      ],
      "source": [
        "encoded_text = token.texts_to_sequences(text)\n",
        "print(encoded_text[:3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "srPMESD4USrM"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "max_length = 120\n",
        "X = pad_sequences(encoded_text, maxlen=max_length, padding='post')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJV0ntWtUXXk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "d = 300\n",
        "word_vector_matrix = np.zeros((vocab_size, d))\n",
        "\n",
        "\n",
        "not_word = []\n",
        "have_word = []\n",
        "\n",
        "for word, index in token.word_index.items()  :# هر کلمه یه شناسه داره\n",
        "    vector = model.get_word_vector(word)\n",
        "    if vector is not None:\n",
        "        word_vector_matrix[index] = vector\n",
        "        have_word.append(word)\n",
        "    else:\n",
        "        not_word.append(word)    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ShkDsSQLZARB"
      },
      "outputs": [],
      "source": [
        "yy = []\n",
        "for x in y:\n",
        "  if x == 1:\n",
        "    yy.append(1)\n",
        "  else:\n",
        "    yy.append(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aTjoVar4UXaN"
      },
      "outputs": [],
      "source": [
        "#Divide texts by labels one and zero\n",
        "df_y = pd.DataFrame(np.array(yy),columns=['a'])\n",
        "df_one = df_y[df_y['a']==1].index.values.astype(int)\n",
        "df_zero = df_y[df_y['a']==0].index.values.astype(int)\n",
        "\n",
        "text_one = []\n",
        "for x in df_one:\n",
        "    text_one.append(text[x])\n",
        "\n",
        "text_zero = []\n",
        "for x in df_zero:\n",
        "    text_zero.append(text[x])\n",
        "\n",
        "join_text_zero = [' '.join(text_zero)]\n",
        "join_text_one = [' '.join(text_one)]\n",
        "\n",
        "df_join_text_zero = pd.DataFrame(join_text_zero[0:],columns= [\"tex\"])\n",
        "df_join_text_one = pd.DataFrame(join_text_one[0:],columns= [\"tex\"])\n",
        "\n",
        "df_have_word = pd.DataFrame({'word':have_word})\n",
        "df_token = pd.DataFrame.from_dict(token.word_index.items())\n",
        "\n",
        "df_text_one = pd.DataFrame(text_one[0:],columns= [\"tex\"])\n",
        "df_text_zero = pd.DataFrame(text_zero[0:],columns= [\"tex\"])\n",
        "\n",
        "from collections import Counter\n",
        "count_zero = df_join_text_zero['tex'].str.split().apply(Counter)\n",
        "count_one = df_join_text_one['tex'].str.split().apply(Counter)\n",
        "\n",
        "df_counter_zero = pd.DataFrame.from_dict(count_zero[0], orient='index').reset_index()\n",
        "df_counter_one = pd.DataFrame.from_dict(count_one[0], orient='index').reset_index()\n",
        "df_counter_zero.columns = ['word', 'value']\n",
        "df_counter_one.columns = ['word', 'value']\n",
        "\n",
        "df_token.columns = ['word', 'id']\n",
        "\n",
        "sentiment_zero =df_have_word.merge(df_counter_zero, left_on='word', right_on='word')[['value','word']]\n",
        "sentiment_one = df_have_word.merge(df_counter_one, left_on='word', right_on='word')[['value','word']]\n",
        "\n",
        "#Words found in both positive and negative sentences\n",
        "common = sentiment_one.merge(sentiment_zero,on=['word','word'])\n",
        "common.columns = ['value_one', 'word' , 'value_zero']\n",
        "\n",
        "common[\"max\"] = common[[\"value_one\", \"value_zero\"]].max(axis=1)\n",
        "common[\"min\"] = common[[\"value_one\", \"value_zero\"]].min(axis=1)\n",
        "\n",
        "\n",
        "common[\"lable\"] = np.where(common[\"value_one\"] == common[\"max\"], 1, 0)\n",
        "common[\"frequent_negative_sentence\"] = np.where(common[\"lable\"] == 1 , common[\"min\"], common[\"max\"])\n",
        "common[\"frequent_positive_sentence\"] = np.where(common[\"lable\"] == 0 , common[\"min\"], common[\"max\"])\n",
        "\n",
        "common_df_final = common.drop('value_one', 1)\n",
        "common_df_final = common_df_final.drop('value_zero', 1)\n",
        "common_df_final = common_df_final.drop('max', 1)\n",
        "common_df_final = common_df_final.drop('min', 1)\n",
        "\n",
        "#Those words that are seen in positive sentences and not seen in negative sentences\n",
        "just_one = sentiment_one[(~sentiment_one.word.isin(common.word))&(~sentiment_one.word.isin(common.word))]\n",
        "just_one = just_one.assign(lable = 1)\n",
        "just_one = just_one.assign(frequent_negative_sentence = 0)\n",
        "just_one.columns = ['frequent_positive_sentence', 'word' , 'lable','frequent_negative_sentence']\n",
        "\n",
        "#Those words that are seen in negative sentences and not seen in positive sentences\n",
        "just_zero = sentiment_zero[(~sentiment_zero.word.isin(common.word))&(~sentiment_zero.word.isin(common.word))]\n",
        "just_zero = just_zero.assign(lable = 0)\n",
        "just_zero = just_zero.assign(frequent_posoitve_sentence = 0)\n",
        "just_zero.columns = ['frequent_negative_sentence', 'word' , 'lable','frequent_positive_sentence']\n",
        "\n",
        "frames = [common_df_final,just_zero, just_one]\n",
        "result = pd.concat(frames)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQc1HykjUXcb"
      },
      "outputs": [],
      "source": [
        "result['WI_positive_word'] = np.where(result['lable']== 1 , 1- result['frequent_negative_sentence']/ result['frequent_positive_sentence'], None)\n",
        "result['WI_negative_word'] = np.where(result['lable']== 0 , 1- result['frequent_positive_sentence']/ result['frequent_negative_sentence'], None)\n",
        "result['WI'] = result['WI_positive_word'].fillna(result['WI_negative_word'])\n",
        "\n",
        "#result.index[result['lable'] == 0].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0NgzkiApc9Qh"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(list(zip(text, y)), columns =['text', 'lable'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2JThyUvcbA8"
      },
      "outputs": [],
      "source": [
        "word_have_list= list(result.word)\n",
        "word_have_set = set(word_have_list)\n",
        "result_word_list = result['word'].tolist()\n",
        "result_WI_list = result['WI'].tolist()\n",
        "\n",
        "def word_WI_finder(x):\n",
        "    df_words = set(x.split(' '))\n",
        "    extract_words =  word_set.intersection(df_words)\n",
        "    #index_word = result_word_list.index(extract_words)\n",
        "    \n",
        "    \n",
        "    return (extract_words)\n",
        "\n",
        "\n",
        "word_set = word_have_set\n",
        "\n",
        "df['ddd_WI'] = df.text.apply(word_WI_finder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYjyFARcczP7"
      },
      "outputs": [],
      "source": [
        "WI_ww = []\n",
        "for x in df['ddd_WI'][:]:\n",
        "    WI_w = []\n",
        "    for y in x : \n",
        "        ind = result_word_list.index(y)\n",
        "        WI_w.append(result_WI_list[ind])\n",
        "    WI_ww.append(WI_w)\n",
        "    \n",
        "WI_ww_new = [[] if x==[0] else x for x in WI_ww]\n",
        "WI_ww_neww = [[] if x==[0,0] else x for x in WI_ww_new]\n",
        "Weight_sentence = [[float(j)/sum(i) for j in i] for i in WI_ww_neww[:]]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1NQbXmvEdjAJ"
      },
      "outputs": [],
      "source": [
        "sentence_ss = []\n",
        "for i in range(len(df['ddd_WI'][:])):\n",
        "    #print(df['ddd_WI'][x])\n",
        "    vv = []\n",
        "    for j in range(len(df['ddd_WI'][i])):\n",
        "        #print(list(df['ddd_WI'][i])[j])\n",
        "        if len(Weight_sentence[i]) > 1:\n",
        "            v = []\n",
        "            for num in range(d):\n",
        "                vec = Weight_sentence[i][j] * float(model.get_word_vector(list(df['ddd_WI'][i])[j])[num])\n",
        "                v.append(vec)\n",
        "            #print(v)\n",
        "            vv.append(v)\n",
        "        #print(vv)\n",
        "        else:\n",
        "            vv.append(model.get_word_vector(list(df['ddd_WI'][i])[j]).astype(np.float))\n",
        "            \n",
        "    s = [sum(x) for x in zip(*vv)]\n",
        "    sentence_ss.append(s)\n",
        "\n",
        "sentence_ss[0]\n",
        "\n",
        "data = pd.DataFrame(sentence_ss[0:] , columns = list(range(d)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9hseZiUZhBJh"
      },
      "outputs": [],
      "source": [
        "r = [a for a in range(len(data))]\n",
        "random.shuffle(r)\n",
        "train_size = int(0.9*(len(r)))\n",
        "test_size = int(0.1*(len(r)))\n",
        "train_index = r[:train_size]\n",
        "test_index = r[train_size:]\n",
        "x_train = data.iloc[train_index]\n",
        "x_test = data.iloc[test_index]\n",
        "\n",
        "li_y_train = [yy[i] for i in train_index]\n",
        "li_y_test = [yy[i] for i in test_index]\n",
        "y_train = pd.DataFrame(li_y_train)\n",
        "y_test = pd.DataFrame(li_y_test)\n",
        "y_train = pd.DataFrame(li_y_train)\n",
        "y_test = pd.DataFrame(li_y_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "IpP1LuU42SvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### save train & test data"
      ],
      "metadata": {
        "id": "hMQV9jN62TL0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.to_csv('x_train.csv')\n",
        "!cp x_train.csv \"drive/My Drive/data/digikala_data/\"\n",
        "\n",
        "y_train.to_csv('y_train.csv')\n",
        "!cp y_train.csv \"drive/My Drive/data/digikala_data/\"\n",
        "\n",
        "x_test.to_csv('x_test.csv')\n",
        "!cp x_test.csv \"drive/My Drive/data/digikala_data/\"\n",
        "\n",
        "y_test.to_csv('y_test.csv')\n",
        "!cp y_test.csv \"drive/My Drive/data/digikala_data/\""
      ],
      "metadata": {
        "id": "J16J42DbpjUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.read_csv('/content/drive/MyDrive/data/digikala_data/y_train.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "rRk9l4MSpNrR",
        "outputId": "8c8d8d47-dc1c-4c1f-f0d5-120e21f84e02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a827af26-65ca-4519-8b84-c7539d95bd2e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47768</th>\n",
              "      <td>47768</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47769</th>\n",
              "      <td>47769</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47770</th>\n",
              "      <td>47770</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47771</th>\n",
              "      <td>47771</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47772</th>\n",
              "      <td>47772</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>47773 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a827af26-65ca-4519-8b84-c7539d95bd2e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a827af26-65ca-4519-8b84-c7539d95bd2e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a827af26-65ca-4519-8b84-c7539d95bd2e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       Unnamed: 0  0\n",
              "0               0  1\n",
              "1               1  1\n",
              "2               2  1\n",
              "3               3  1\n",
              "4               4  1\n",
              "...           ... ..\n",
              "47768       47768  1\n",
              "47769       47769  1\n",
              "47770       47770  1\n",
              "47771       47771  1\n",
              "47772       47772  0\n",
              "\n",
              "[47773 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparation data "
      ],
      "metadata": {
        "id": "aW2CA8FIpN4s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "x_train = pd.read_csv('/content/drive/MyDrive/data/digikala_data/x_train.csv')\n",
        "x_train = x_train.drop('Unnamed: 0', 1)\n",
        "\n",
        "y_train = pd.read_csv('/content/drive/MyDrive/data/digikala_data/y_train.csv')\n",
        "y_train = y_train.drop('Unnamed: 0', 1)\n",
        "\n",
        "x_test = pd.read_csv('/content/drive/MyDrive/data/digikala_data/x_test.csv')\n",
        "x_test = x_test.drop('Unnamed: 0', 1)\n",
        "\n",
        "y_test = pd.read_csv('/content/drive/MyDrive/data/digikala_data/y_test.csv')\n",
        "y_test = y_test.drop('Unnamed: 0', 1)"
      ],
      "metadata": {
        "id": "b6Njq_rzpd_t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a131c28a-528e-4afc-c201-004551b82854"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  del sys.path[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.fillna(0)\n",
        "y_train = y_train.fillna(0)\n",
        "x_test = x_test.fillna(0)\n",
        "y_test = y_test.fillna(0)\n"
      ],
      "metadata": {
        "id": "YZ0iklh5qkdc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CNN"
      ],
      "metadata": {
        "id": "HLpJAUUC7SFz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import optimizers\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Input, Embedding, Dropout\n",
        "from keras.layers import GlobalMaxPool1D, MaxPooling1D, GlobalMaxPooling1D\n",
        "from keras.layers import CuDNNLSTM, LSTM, Bidirectional\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D, Dropout, Dense, Flatten, LSTM, MaxPooling1D, Bidirectional,Conv2D\n",
        "from keras.callbacks import EarlyStopping, TensorBoard\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D, Dropout, Dense, Flatten, LSTM, MaxPooling1D, Bidirectional\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping, TensorBoard"
      ],
      "metadata": {
        "id": "2lGVkZjz7KE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#https://stackoverflow.com/questions/62475807/cnn-on-tfidf-as-input\n",
        "# create model\n",
        "inp = Input(shape=(1,300))\n",
        "conv2 = Conv1D(filters=128, kernel_size=5, activation='relu', padding='same')(inp)\n",
        "drop21 = Dropout(0.2)(conv2)\n",
        "\n",
        "conv22 = Conv1D(filters=64, kernel_size=5, activation='relu', padding='same')(drop21)\n",
        "drop22 = Dropout(0.2)(conv22)\n",
        "conv23 = Conv1D(filters=32, kernel_size=5, activation='relu', padding='same')(drop22)\n",
        "drop23 = Dropout(0.2)(conv23)\n",
        "conv24 = Conv1D(filters=16, kernel_size=5, activation='relu', padding='same')(drop23)\n",
        "drop24 = Dropout(0.2)(conv24)\n",
        "\n",
        "pool2 = Flatten()(drop24) # this is an option to pass from 3d to 2d\n",
        "out = Dense(2, activation='softmax')(pool2) # the output dim must be equal to the num of class if u use softmax\n",
        "\n",
        "model = Model(inp, out)\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "model.fit(np.expand_dims(np.array(x_train), axis=1), np.array(y_train).flatten(), epochs=200)"
      ],
      "metadata": {
        "id": "nd1rG6lk7K77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd6792d2-3eb7-4989-d800-9fdbf0ccfb54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1, 300)]          0         \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 1, 128)            192128    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1, 128)            0         \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 1, 64)             41024     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 1, 64)             0         \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 1, 32)             10272     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 1, 32)             0         \n",
            "                                                                 \n",
            " conv1d_3 (Conv1D)           (None, 1, 16)             2576      \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 1, 16)             0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 16)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 34        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 246,034\n",
            "Trainable params: 246,034\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "1493/1493 [==============================] - 12s 7ms/step - loss: 0.3732 - accuracy: 0.8355\n",
            "Epoch 2/200\n",
            "1493/1493 [==============================] - 11s 7ms/step - loss: 0.3256 - accuracy: 0.8625\n",
            "Epoch 3/200\n",
            "1493/1493 [==============================] - 10s 7ms/step - loss: 0.3140 - accuracy: 0.8675\n",
            "Epoch 4/200\n",
            "1493/1493 [==============================] - 11s 7ms/step - loss: 0.3065 - accuracy: 0.8718\n",
            "Epoch 5/200\n",
            "1493/1493 [==============================] - 12s 8ms/step - loss: 0.2981 - accuracy: 0.8745\n",
            "Epoch 6/200\n",
            "1493/1493 [==============================] - 11s 7ms/step - loss: 0.2921 - accuracy: 0.8755\n",
            "Epoch 7/200\n",
            "1493/1493 [==============================] - 10s 7ms/step - loss: 0.2869 - accuracy: 0.8789\n",
            "Epoch 8/200\n",
            "1493/1493 [==============================] - 10s 7ms/step - loss: 0.2808 - accuracy: 0.8820\n",
            "Epoch 9/200\n",
            "1493/1493 [==============================] - 11s 7ms/step - loss: 0.2753 - accuracy: 0.8840\n",
            "Epoch 10/200\n",
            "1493/1493 [==============================] - 11s 7ms/step - loss: 0.2708 - accuracy: 0.8858\n",
            "Epoch 11/200\n",
            "1493/1493 [==============================] - 11s 7ms/step - loss: 0.2662 - accuracy: 0.8890\n",
            "Epoch 12/200\n",
            "1493/1493 [==============================] - 10s 7ms/step - loss: 0.2621 - accuracy: 0.8903\n",
            "Epoch 13/200\n",
            "1493/1493 [==============================] - 10s 6ms/step - loss: 0.2569 - accuracy: 0.8921\n",
            "Epoch 14/200\n",
            "1493/1493 [==============================] - 10s 7ms/step - loss: 0.2549 - accuracy: 0.8935\n",
            "Epoch 15/200\n",
            "1493/1493 [==============================] - 10s 7ms/step - loss: 0.2484 - accuracy: 0.8967\n",
            "Epoch 16/200\n",
            "1493/1493 [==============================] - 10s 7ms/step - loss: 0.2457 - accuracy: 0.8976\n",
            "Epoch 17/200\n",
            "1493/1493 [==============================] - 11s 8ms/step - loss: 0.2426 - accuracy: 0.8999\n",
            "Epoch 18/200\n",
            "1493/1493 [==============================] - 10s 6ms/step - loss: 0.2367 - accuracy: 0.9017\n",
            "Epoch 19/200\n",
            "1493/1493 [==============================] - 10s 7ms/step - loss: 0.2351 - accuracy: 0.9031\n",
            "Epoch 20/200\n",
            "1493/1493 [==============================] - 10s 7ms/step - loss: 0.2303 - accuracy: 0.9047\n",
            "Epoch 21/200\n",
            "1493/1493 [==============================] - 10s 7ms/step - loss: 0.2289 - accuracy: 0.9067\n",
            "Epoch 22/200\n",
            "1493/1493 [==============================] - 10s 7ms/step - loss: 0.2257 - accuracy: 0.9077\n",
            "Epoch 23/200\n",
            "1493/1493 [==============================] - 11s 7ms/step - loss: 0.2224 - accuracy: 0.9088\n",
            "Epoch 24/200\n",
            "1493/1493 [==============================] - 10s 7ms/step - loss: 0.2202 - accuracy: 0.9095\n",
            "Epoch 25/200\n",
            "1493/1493 [==============================] - 10s 6ms/step - loss: 0.2169 - accuracy: 0.9113\n",
            "Epoch 26/200\n",
            "1493/1493 [==============================] - 10s 7ms/step - loss: 0.2161 - accuracy: 0.9120\n",
            "Epoch 27/200\n",
            "1493/1493 [==============================] - 10s 7ms/step - loss: 0.2127 - accuracy: 0.9135\n",
            "Epoch 28/200\n",
            "1493/1493 [==============================] - 10s 7ms/step - loss: 0.2078 - accuracy: 0.9161\n",
            "Epoch 29/200\n",
            "1493/1493 [==============================] - 10s 6ms/step - loss: 0.2045 - accuracy: 0.9165\n",
            "Epoch 30/200\n",
            "1493/1493 [==============================] - 9s 6ms/step - loss: 0.2041 - accuracy: 0.9179\n",
            "Epoch 31/200\n",
            "1493/1493 [==============================] - 10s 7ms/step - loss: 0.1995 - accuracy: 0.9195\n",
            "Epoch 32/200\n",
            "1493/1493 [==============================] - 9s 6ms/step - loss: 0.1990 - accuracy: 0.9198\n",
            "Epoch 33/200\n",
            "1493/1493 [==============================] - 10s 7ms/step - loss: 0.1953 - accuracy: 0.9213\n",
            "Epoch 34/200\n",
            "1493/1493 [==============================] - 10s 7ms/step - loss: 0.1946 - accuracy: 0.9201\n",
            "Epoch 35/200\n",
            "1493/1493 [==============================] - 10s 6ms/step - loss: 0.1915 - accuracy: 0.9245\n",
            "Epoch 36/200\n",
            "1493/1493 [==============================] - 10s 6ms/step - loss: 0.1899 - accuracy: 0.9251\n",
            "Epoch 37/200\n",
            "1493/1493 [==============================] - 10s 7ms/step - loss: 0.1876 - accuracy: 0.9262\n",
            "Epoch 38/200\n",
            "1493/1493 [==============================] - 9s 6ms/step - loss: 0.1862 - accuracy: 0.9247\n",
            "Epoch 39/200\n",
            "1493/1493 [==============================] - 10s 7ms/step - loss: 0.1809 - accuracy: 0.9287\n",
            "Epoch 40/200\n",
            "1493/1493 [==============================] - 11s 8ms/step - loss: 0.1823 - accuracy: 0.9273\n",
            "Epoch 41/200\n",
            "1493/1493 [==============================] - 10s 7ms/step - loss: 0.1808 - accuracy: 0.9277\n",
            "Epoch 42/200\n",
            "1493/1493 [==============================] - 10s 6ms/step - loss: 0.1792 - accuracy: 0.9286\n",
            "Epoch 43/200\n",
            "1493/1493 [==============================] - 10s 6ms/step - loss: 0.1765 - accuracy: 0.9310\n",
            "Epoch 44/200\n",
            "1493/1493 [==============================] - 11s 7ms/step - loss: 0.1746 - accuracy: 0.9304\n",
            "Epoch 45/200\n",
            "1493/1493 [==============================] - 11s 7ms/step - loss: 0.1754 - accuracy: 0.9311\n",
            "Epoch 46/200\n",
            "1493/1493 [==============================] - 12s 8ms/step - loss: 0.1694 - accuracy: 0.9338\n",
            "Epoch 47/200\n",
            "1493/1493 [==============================] - 11s 7ms/step - loss: 0.1704 - accuracy: 0.9335\n",
            "Epoch 48/200\n",
            "1493/1493 [==============================] - 11s 7ms/step - loss: 0.1698 - accuracy: 0.9330\n",
            "Epoch 49/200\n",
            "1493/1493 [==============================] - 10s 6ms/step - loss: 0.1667 - accuracy: 0.9349\n",
            "Epoch 50/200\n",
            "1493/1493 [==============================] - 9s 6ms/step - loss: 0.1661 - accuracy: 0.9346\n",
            "Epoch 51/200\n",
            "1493/1493 [==============================] - 9s 6ms/step - loss: 0.1643 - accuracy: 0.9358\n",
            "Epoch 52/200\n",
            "1493/1493 [==============================] - 10s 7ms/step - loss: 0.1612 - accuracy: 0.9368\n",
            "Epoch 53/200\n",
            "1493/1493 [==============================] - 11s 7ms/step - loss: 0.1609 - accuracy: 0.9374\n",
            "Epoch 54/200\n",
            "1493/1493 [==============================] - 11s 7ms/step - loss: 0.1588 - accuracy: 0.9384\n",
            "Epoch 55/200\n",
            "1493/1493 [==============================] - 11s 7ms/step - loss: 0.1576 - accuracy: 0.9396\n",
            "Epoch 56/200\n",
            "1493/1493 [==============================] - 11s 7ms/step - loss: 0.1565 - accuracy: 0.9392\n",
            "Epoch 57/200\n",
            "1493/1493 [==============================] - 11s 7ms/step - loss: 0.1546 - accuracy: 0.9398\n",
            "Epoch 58/200\n",
            "1493/1493 [==============================] - 13s 9ms/step - loss: 0.1554 - accuracy: 0.9393\n",
            "Epoch 59/200\n",
            "1493/1493 [==============================] - 12s 8ms/step - loss: 0.1516 - accuracy: 0.9405\n",
            "Epoch 60/200\n",
            "1493/1493 [==============================] - 12s 8ms/step - loss: 0.1544 - accuracy: 0.9404\n",
            "Epoch 61/200\n",
            "1493/1493 [==============================] - 12s 8ms/step - loss: 0.1494 - accuracy: 0.9427\n",
            "Epoch 62/200\n",
            "1493/1493 [==============================] - 12s 8ms/step - loss: 0.1495 - accuracy: 0.9419\n",
            "Epoch 63/200\n",
            "1493/1493 [==============================] - 12s 8ms/step - loss: 0.1504 - accuracy: 0.9424\n",
            "Epoch 64/200\n",
            "1493/1493 [==============================] - 12s 8ms/step - loss: 0.1484 - accuracy: 0.9428\n",
            "Epoch 65/200\n",
            "1493/1493 [==============================] - 11s 7ms/step - loss: 0.1471 - accuracy: 0.9439\n",
            "Epoch 66/200\n",
            "1493/1493 [==============================] - 11s 8ms/step - loss: 0.1461 - accuracy: 0.9434\n",
            "Epoch 67/200\n",
            "1493/1493 [==============================] - 11s 7ms/step - loss: 0.1441 - accuracy: 0.9456\n",
            "Epoch 68/200\n",
            "1493/1493 [==============================] - 12s 8ms/step - loss: 0.1444 - accuracy: 0.9449\n",
            "Epoch 69/200\n",
            "1493/1493 [==============================] - 11s 7ms/step - loss: 0.1437 - accuracy: 0.9454\n",
            "Epoch 70/200\n",
            "1493/1493 [==============================] - 12s 8ms/step - loss: 0.1421 - accuracy: 0.9464\n",
            "Epoch 71/200\n",
            "1493/1493 [==============================] - 12s 8ms/step - loss: 0.1389 - accuracy: 0.9467\n",
            "Epoch 72/200\n",
            "1493/1493 [==============================] - 12s 8ms/step - loss: 0.1409 - accuracy: 0.9464\n",
            "Epoch 73/200\n",
            "1493/1493 [==============================] - 12s 8ms/step - loss: 0.1388 - accuracy: 0.9478\n",
            "Epoch 74/200\n",
            "1493/1493 [==============================] - 12s 8ms/step - loss: 0.1390 - accuracy: 0.9476\n",
            "Epoch 75/200\n",
            "1493/1493 [==============================] - 12s 8ms/step - loss: 0.1344 - accuracy: 0.9497\n",
            "Epoch 76/200\n",
            "1493/1493 [==============================] - 12s 8ms/step - loss: 0.1363 - accuracy: 0.9478\n",
            "Epoch 77/200\n",
            "1493/1493 [==============================] - 11s 7ms/step - loss: 0.1399 - accuracy: 0.9471\n",
            "Epoch 78/200\n",
            "1493/1493 [==============================] - 12s 8ms/step - loss: 0.1348 - accuracy: 0.9485\n",
            "Epoch 79/200\n",
            "1493/1493 [==============================] - 12s 8ms/step - loss: 0.1344 - accuracy: 0.9496\n",
            "Epoch 80/200\n",
            "1493/1493 [==============================] - 11s 8ms/step - loss: 0.1321 - accuracy: 0.9499\n",
            "Epoch 81/200\n",
            "1493/1493 [==============================] - 12s 8ms/step - loss: 0.1328 - accuracy: 0.9497\n",
            "Epoch 82/200\n",
            "1493/1493 [==============================] - 11s 7ms/step - loss: 0.1317 - accuracy: 0.9513\n",
            "Epoch 83/200\n",
            "1493/1493 [==============================] - 11s 8ms/step - loss: 0.1306 - accuracy: 0.9506\n",
            "Epoch 84/200\n",
            "1493/1493 [==============================] - 11s 8ms/step - loss: 0.1273 - accuracy: 0.9521\n",
            "Epoch 85/200\n",
            "1493/1493 [==============================] - 11s 7ms/step - loss: 0.1268 - accuracy: 0.9520\n",
            "Epoch 86/200\n",
            "1493/1493 [==============================] - 12s 8ms/step - loss: 0.1275 - accuracy: 0.9517\n",
            "Epoch 87/200\n",
            "1493/1493 [==============================] - 13s 9ms/step - loss: 0.1300 - accuracy: 0.9519\n",
            "Epoch 88/200\n",
            "1493/1493 [==============================] - 12s 8ms/step - loss: 0.1256 - accuracy: 0.9527\n",
            "Epoch 89/200\n",
            "1493/1493 [==============================] - 11s 7ms/step - loss: 0.1265 - accuracy: 0.9523\n",
            "Epoch 90/200\n",
            "1493/1493 [==============================] - 11s 8ms/step - loss: 0.1272 - accuracy: 0.9531\n",
            "Epoch 91/200\n",
            "1493/1493 [==============================] - 10s 7ms/step - loss: 0.1227 - accuracy: 0.9542\n",
            "Epoch 92/200\n",
            "1493/1493 [==============================] - 11s 8ms/step - loss: 0.1249 - accuracy: 0.9530\n",
            "Epoch 93/200\n",
            "1493/1493 [==============================] - 11s 7ms/step - loss: 0.1228 - accuracy: 0.9545\n",
            "Epoch 94/200\n",
            "1493/1493 [==============================] - 11s 8ms/step - loss: 0.1213 - accuracy: 0.9554\n",
            "Epoch 95/200\n",
            "1493/1493 [==============================] - 12s 8ms/step - loss: 0.1213 - accuracy: 0.9546\n",
            "Epoch 96/200\n",
            "1493/1493 [==============================] - 11s 7ms/step - loss: 0.1247 - accuracy: 0.9532\n",
            "Epoch 97/200\n",
            "1493/1493 [==============================] - 11s 7ms/step - loss: 0.1195 - accuracy: 0.9553\n",
            "Epoch 98/200\n",
            "1493/1493 [==============================] - 11s 7ms/step - loss: 0.1187 - accuracy: 0.9565\n",
            "Epoch 99/200\n",
            "1493/1493 [==============================] - 10s 7ms/step - loss: 0.1200 - accuracy: 0.9562\n",
            "Epoch 100/200\n",
            "1493/1493 [==============================] - 11s 7ms/step - loss: 0.1197 - accuracy: 0.9548\n",
            "Epoch 101/200\n",
            "1493/1493 [==============================] - 11s 8ms/step - loss: 0.1169 - accuracy: 0.9566\n",
            "Epoch 102/200\n",
            "1493/1493 [==============================] - 11s 7ms/step - loss: 0.1171 - accuracy: 0.9571\n",
            "Epoch 103/200\n",
            "1493/1493 [==============================] - 11s 7ms/step - loss: 0.1206 - accuracy: 0.9558\n",
            "Epoch 104/200\n",
            "1493/1493 [==============================] - 12s 8ms/step - loss: 0.1183 - accuracy: 0.9556\n",
            "Epoch 105/200\n",
            "1493/1493 [==============================] - 11s 7ms/step - loss: 0.1176 - accuracy: 0.9561\n",
            "Epoch 106/200\n",
            "1493/1493 [==============================] - 11s 7ms/step - loss: 0.1163 - accuracy: 0.9579\n",
            "Epoch 107/200\n",
            "1493/1493 [==============================] - 11s 7ms/step - loss: 0.1141 - accuracy: 0.9576\n",
            "Epoch 108/200\n",
            "1493/1493 [==============================] - 12s 8ms/step - loss: 0.1171 - accuracy: 0.9570\n",
            "Epoch 109/200\n",
            "1493/1493 [==============================] - 11s 7ms/step - loss: 0.1146 - accuracy: 0.9573\n",
            "Epoch 110/200\n",
            "1493/1493 [==============================] - 12s 8ms/step - loss: 0.1119 - accuracy: 0.9589\n",
            "Epoch 111/200\n",
            "1493/1493 [==============================] - 15s 10ms/step - loss: 0.1122 - accuracy: 0.9577\n",
            "Epoch 112/200\n",
            "1493/1493 [==============================] - 13s 9ms/step - loss: 0.1088 - accuracy: 0.9597\n",
            "Epoch 113/200\n",
            "1493/1493 [==============================] - 12s 8ms/step - loss: 0.1132 - accuracy: 0.9594\n",
            "Epoch 114/200\n",
            "1493/1493 [==============================] - 11s 8ms/step - loss: 0.1124 - accuracy: 0.9590\n",
            "Epoch 115/200\n",
            "1493/1493 [==============================] - 11s 8ms/step - loss: 0.1108 - accuracy: 0.9587\n",
            "Epoch 116/200\n",
            "1493/1493 [==============================] - 11s 7ms/step - loss: 0.1090 - accuracy: 0.9604\n",
            "Epoch 117/200\n",
            "1493/1493 [==============================] - 11s 7ms/step - loss: 0.1099 - accuracy: 0.9591\n",
            "Epoch 118/200\n",
            "1493/1493 [==============================] - 11s 7ms/step - loss: 0.1098 - accuracy: 0.9593\n",
            "Epoch 119/200\n",
            "1493/1493 [==============================] - 10s 7ms/step - loss: 0.1090 - accuracy: 0.9617\n",
            "Epoch 120/200\n",
            "1493/1493 [==============================] - 10s 7ms/step - loss: 0.1096 - accuracy: 0.9602\n",
            "Epoch 121/200\n",
            "1493/1493 [==============================] - 10s 7ms/step - loss: 0.1108 - accuracy: 0.9614\n",
            "Epoch 122/200\n",
            "1493/1493 [==============================] - 10s 7ms/step - loss: 0.1064 - accuracy: 0.9613\n",
            "Epoch 123/200\n",
            "1493/1493 [==============================] - 10s 7ms/step - loss: 0.1073 - accuracy: 0.9612\n",
            "Epoch 124/200\n",
            "1493/1493 [==============================] - 10s 7ms/step - loss: 0.1083 - accuracy: 0.9611\n",
            "Epoch 125/200\n",
            "1493/1493 [==============================] - 11s 7ms/step - loss: 0.1037 - accuracy: 0.9620\n",
            "Epoch 126/200\n",
            "1493/1493 [==============================] - 12s 8ms/step - loss: 0.1071 - accuracy: 0.9618\n",
            "Epoch 127/200\n",
            "1493/1493 [==============================] - 10s 7ms/step - loss: 0.1031 - accuracy: 0.9620\n",
            "Epoch 128/200\n",
            "1493/1493 [==============================] - 11s 7ms/step - loss: 0.1067 - accuracy: 0.9602\n",
            "Epoch 129/200\n",
            "1493/1493 [==============================] - 13s 9ms/step - loss: 0.1047 - accuracy: 0.9627\n",
            "Epoch 130/200\n",
            "1493/1493 [==============================] - 12s 8ms/step - loss: 0.1025 - accuracy: 0.9634\n",
            "Epoch 131/200\n",
            "1493/1493 [==============================] - 12s 8ms/step - loss: 0.1055 - accuracy: 0.9618\n",
            "Epoch 132/200\n",
            "1493/1493 [==============================] - 11s 8ms/step - loss: 0.1034 - accuracy: 0.9629\n",
            "Epoch 133/200\n",
            "1493/1493 [==============================] - 11s 7ms/step - loss: 0.1054 - accuracy: 0.9617\n",
            "Epoch 134/200\n",
            "1493/1493 [==============================] - 12s 8ms/step - loss: 0.1019 - accuracy: 0.9630\n",
            "Epoch 135/200\n",
            "1493/1493 [==============================] - 11s 7ms/step - loss: 0.1015 - accuracy: 0.9632\n",
            "Epoch 136/200\n",
            "1493/1493 [==============================] - 12s 8ms/step - loss: 0.1043 - accuracy: 0.9629\n",
            "Epoch 137/200\n",
            "1493/1493 [==============================] - 12s 8ms/step - loss: 0.1024 - accuracy: 0.9635\n",
            "Epoch 138/200\n",
            "1493/1493 [==============================] - 11s 8ms/step - loss: 0.1010 - accuracy: 0.9632\n",
            "Epoch 139/200\n",
            "1493/1493 [==============================] - 13s 9ms/step - loss: 0.1003 - accuracy: 0.9636\n",
            "Epoch 140/200\n",
            "1493/1493 [==============================] - 12s 8ms/step - loss: 0.1005 - accuracy: 0.9641\n",
            "Epoch 141/200\n",
            "1493/1493 [==============================] - 11s 7ms/step - loss: 0.1008 - accuracy: 0.9637\n",
            "Epoch 142/200\n",
            "1493/1493 [==============================] - 11s 7ms/step - loss: 0.1002 - accuracy: 0.9637\n",
            "Epoch 143/200\n",
            "1493/1493 [==============================] - 11s 7ms/step - loss: 0.1011 - accuracy: 0.9642\n",
            "Epoch 144/200\n",
            "1493/1493 [==============================] - 11s 7ms/step - loss: 0.1014 - accuracy: 0.9642\n",
            "Epoch 145/200\n",
            "1493/1493 [==============================] - 11s 7ms/step - loss: 0.1003 - accuracy: 0.9646\n",
            "Epoch 146/200\n",
            "1493/1493 [==============================] - 11s 7ms/step - loss: 0.1013 - accuracy: 0.9639\n",
            "Epoch 147/200\n",
            "1493/1493 [==============================] - 10s 7ms/step - loss: 0.1003 - accuracy: 0.9641\n",
            "Epoch 148/200\n",
            "1493/1493 [==============================] - 10s 7ms/step - loss: 0.0965 - accuracy: 0.9653\n",
            "Epoch 149/200\n",
            "1493/1493 [==============================] - 10s 7ms/step - loss: 0.0958 - accuracy: 0.9660\n",
            "Epoch 150/200\n",
            "1493/1493 [==============================] - 11s 7ms/step - loss: 0.1010 - accuracy: 0.9647\n",
            "Epoch 151/200\n",
            "1493/1493 [==============================] - 12s 8ms/step - loss: 0.0994 - accuracy: 0.9642\n",
            "Epoch 152/200\n",
            "1493/1493 [==============================] - 13s 8ms/step - loss: 0.0965 - accuracy: 0.9651\n",
            "Epoch 153/200\n",
            "1493/1493 [==============================] - 12s 8ms/step - loss: 0.0965 - accuracy: 0.9655\n",
            "Epoch 154/200\n",
            "1493/1493 [==============================] - 12s 8ms/step - loss: 0.0936 - accuracy: 0.9664\n",
            "Epoch 155/200\n",
            "1493/1493 [==============================] - 11s 7ms/step - loss: 0.0962 - accuracy: 0.9658\n",
            "Epoch 156/200\n",
            "1493/1493 [==============================] - 11s 8ms/step - loss: 0.0944 - accuracy: 0.9660\n",
            "Epoch 157/200\n",
            "1493/1493 [==============================] - 12s 8ms/step - loss: 0.0982 - accuracy: 0.9646\n",
            "Epoch 158/200\n",
            "1493/1493 [==============================] - 12s 8ms/step - loss: 0.0984 - accuracy: 0.9654\n",
            "Epoch 159/200\n",
            "1493/1493 [==============================] - 11s 8ms/step - loss: 0.0942 - accuracy: 0.9671\n",
            "Epoch 160/200\n",
            "1493/1493 [==============================] - 12s 8ms/step - loss: 0.0991 - accuracy: 0.9649\n",
            "Epoch 161/200\n",
            "1493/1493 [==============================] - 11s 8ms/step - loss: 0.0969 - accuracy: 0.9660\n",
            "Epoch 162/200\n",
            "1493/1493 [==============================] - 11s 7ms/step - loss: 0.0929 - accuracy: 0.9672\n",
            "Epoch 163/200\n",
            "1493/1493 [==============================] - 11s 7ms/step - loss: 0.0943 - accuracy: 0.9669\n",
            "Epoch 164/200\n",
            "1493/1493 [==============================] - 11s 7ms/step - loss: 0.0922 - accuracy: 0.9665\n",
            "Epoch 165/200\n",
            "1493/1493 [==============================] - 12s 8ms/step - loss: 0.0903 - accuracy: 0.9682\n",
            "Epoch 166/200\n",
            "1493/1493 [==============================] - 11s 8ms/step - loss: 0.0925 - accuracy: 0.9663\n",
            "Epoch 167/200\n",
            "1493/1493 [==============================] - 11s 8ms/step - loss: 0.0927 - accuracy: 0.9670\n",
            "Epoch 168/200\n",
            "1493/1493 [==============================] - 11s 7ms/step - loss: 0.0925 - accuracy: 0.9669\n",
            "Epoch 169/200\n",
            "1493/1493 [==============================] - 10s 7ms/step - loss: 0.0939 - accuracy: 0.9667\n",
            "Epoch 170/200\n",
            "1493/1493 [==============================] - 11s 7ms/step - loss: 0.0913 - accuracy: 0.9667\n",
            "Epoch 171/200\n",
            "1493/1493 [==============================] - 12s 8ms/step - loss: 0.0937 - accuracy: 0.9679\n",
            "Epoch 172/200\n",
            "1493/1493 [==============================] - 12s 8ms/step - loss: 0.0913 - accuracy: 0.9673\n",
            "Epoch 173/200\n",
            "1493/1493 [==============================] - 12s 8ms/step - loss: 0.0917 - accuracy: 0.9673\n",
            "Epoch 174/200\n",
            "1493/1493 [==============================] - 12s 8ms/step - loss: 0.0920 - accuracy: 0.9673\n",
            "Epoch 175/200\n",
            "1493/1493 [==============================] - 14s 10ms/step - loss: 0.0926 - accuracy: 0.9684\n",
            "Epoch 176/200\n",
            "1493/1493 [==============================] - 13s 9ms/step - loss: 0.0929 - accuracy: 0.9672\n",
            "Epoch 177/200\n",
            "1493/1493 [==============================] - 12s 8ms/step - loss: 0.0905 - accuracy: 0.9675\n",
            "Epoch 178/200\n",
            "1493/1493 [==============================] - 11s 8ms/step - loss: 0.0851 - accuracy: 0.9690\n",
            "Epoch 179/200\n",
            "1493/1493 [==============================] - 12s 8ms/step - loss: 0.0917 - accuracy: 0.9672\n",
            "Epoch 180/200\n",
            "1493/1493 [==============================] - 12s 8ms/step - loss: 0.0888 - accuracy: 0.9691\n",
            "Epoch 181/200\n",
            "1493/1493 [==============================] - 11s 7ms/step - loss: 0.0894 - accuracy: 0.9682\n",
            "Epoch 182/200\n",
            "1493/1493 [==============================] - 11s 8ms/step - loss: 0.0899 - accuracy: 0.9679\n",
            "Epoch 183/200\n",
            "1493/1493 [==============================] - 11s 7ms/step - loss: 0.0867 - accuracy: 0.9694\n",
            "Epoch 184/200\n",
            "1493/1493 [==============================] - 11s 8ms/step - loss: 0.0891 - accuracy: 0.9686\n",
            "Epoch 185/200\n",
            "1493/1493 [==============================] - 12s 8ms/step - loss: 0.0882 - accuracy: 0.9687\n",
            "Epoch 186/200\n",
            "1493/1493 [==============================] - 10s 7ms/step - loss: 0.0870 - accuracy: 0.9698\n",
            "Epoch 187/200\n",
            "1493/1493 [==============================] - 11s 7ms/step - loss: 0.0903 - accuracy: 0.9680\n",
            "Epoch 188/200\n",
            "1493/1493 [==============================] - 11s 8ms/step - loss: 0.0859 - accuracy: 0.9699\n",
            "Epoch 189/200\n",
            "1493/1493 [==============================] - 11s 7ms/step - loss: 0.0900 - accuracy: 0.9680\n",
            "Epoch 190/200\n",
            "1493/1493 [==============================] - 11s 7ms/step - loss: 0.0881 - accuracy: 0.9686\n",
            "Epoch 191/200\n",
            "1493/1493 [==============================] - 11s 7ms/step - loss: 0.0879 - accuracy: 0.9687\n",
            "Epoch 192/200\n",
            "1493/1493 [==============================] - 11s 7ms/step - loss: 0.0887 - accuracy: 0.9687\n",
            "Epoch 193/200\n",
            "1493/1493 [==============================] - 11s 7ms/step - loss: 0.0868 - accuracy: 0.9690\n",
            "Epoch 194/200\n",
            "1493/1493 [==============================] - 12s 8ms/step - loss: 0.0865 - accuracy: 0.9692\n",
            "Epoch 195/200\n",
            "1493/1493 [==============================] - 11s 7ms/step - loss: 0.0888 - accuracy: 0.9684\n",
            "Epoch 196/200\n",
            "1493/1493 [==============================] - 11s 8ms/step - loss: 0.0858 - accuracy: 0.9697\n",
            "Epoch 197/200\n",
            "1493/1493 [==============================] - 10s 7ms/step - loss: 0.0856 - accuracy: 0.9698\n",
            "Epoch 198/200\n",
            "1493/1493 [==============================] - 11s 7ms/step - loss: 0.0848 - accuracy: 0.9700\n",
            "Epoch 199/200\n",
            "1493/1493 [==============================] - 11s 7ms/step - loss: 0.0879 - accuracy: 0.9689\n",
            "Epoch 200/200\n",
            "1493/1493 [==============================] - 11s 7ms/step - loss: 0.0867 - accuracy: 0.9698\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f70d27fec90>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(np.expand_dims(np.array(x_test), axis=1), np.array(y_test).flatten(), batch_size=32, verbose=1)"
      ],
      "metadata": {
        "id": "myJ2wVb07VWD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6315962-ec94-434a-95d2-fdbc03dd241a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "166/166 [==============================] - 1s 2ms/step - loss: 0.6579 - accuracy: 0.8623\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6579249501228333, 0.8623092770576477]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **classification**"
      ],
      "metadata": {
        "id": "pn8gwtMV1YXh"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnOyG5AcbAir"
      },
      "source": [
        "### xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YEMmFgrDjOQ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eedab39c-3c28-4ebf-b651-f195003d64c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30.646072706724432\n"
          ]
        }
      ],
      "source": [
        "import xgboost as xgb\n",
        "dtrain = xgb.DMatrix(x_train , label = y_train)\n",
        "dtest = xgb.DMatrix(x_test , label = y_test)\n",
        "param = {\n",
        "    'max_depth': 10,  # the maximum depth of each tree\n",
        "    'eta': 0.1,  # the training step for each iteration\n",
        "    #'silent': 1,  # logging mode - quiet\n",
        "    'objective': 'binary:logistic',  \n",
        "    'eval_metric': 'error',\n",
        "    #'num_class': 2}  # the number of classes that exist in this datset\n",
        "}\n",
        "\n",
        "num_round = 500  # the number of training iterations\n",
        "bst = xgb.train(param, dtrain, num_round)\n",
        "preds = bst.predict(dtest)\n",
        "import numpy as np\n",
        "best_preds = np.asarray([np.argmax(line) for line in preds])\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(y_test, best_preds , normalize=True)*100)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LogisticRegression"
      ],
      "metadata": {
        "id": "HIa-bRVB7_cp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "clf = LogisticRegression(random_state=0,solver='lbfgs', max_iter=100 ).fit(x_train, y_train.values.ravel())\n",
        "y_pred = clf.predict(x_test)\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "cDZGyntD8AQ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96936571-b54e-4ef4-90b1-396c96a9f530"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8527029572424185"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MLPClassifier"
      ],
      "metadata": {
        "id": "Mhounpfs8GRZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(7, 2), random_state=1)\n",
        "clf.fit(x_train, y_train.values.ravel())\n",
        "y_pred = clf.predict(x_test)\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "PgWEVa8e8HZk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74ca7d97-9d2e-4242-ee47-aa2b3197d868"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6935392729327557"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DecisionTree"
      ],
      "metadata": {
        "id": "E1MZtoBo8I5o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import tree\n",
        "clf = tree.DecisionTreeClassifier()\n",
        "clf = clf.fit(x_train, y_train)\n",
        "y_pred = clf.predict(x_test)\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "n74KJZ1p8Mfw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f885c4f-74e3-4424-a91b-18433979057f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7291391975889998"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### KNN"
      ],
      "metadata": {
        "id": "GT2_TkQu7s7c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "classifier = KNeighborsClassifier(n_neighbors=5, metric='minkowski')\n",
        "classifier.fit(x_train, y_train.values.ravel())\n",
        "y_pred = classifier.predict(x_test)\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "ltXx13um7u7J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bffb1b52-710f-4617-ee99-521351503e9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7894142022979845"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVM"
      ],
      "metadata": {
        "id": "6fbj-Mx47vdB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "clf = svm.SVC()\n",
        "clf.fit(x_train, y_train.values.ravel())\n",
        "y_pred = clf.predict(x_test)\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "huDiqSIj7xIx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92559a6c-66cc-4dd4-a4c7-a89d538aee42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8730457713317009"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    }
  ]
}